{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import permutation\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# GPU 강제 할당\n",
    "# 사용 가능한 GPU 목록을 가져온다.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        # 필요한 만큼만 메모리를 사용할 수 있도록 설정한다.\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤시드\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용하는 이미지의 사이즈\n",
    "img_rows = 224\n",
    "img_cols = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 모드\n",
    "run_type = 'train'\n",
    "# run_type = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9층 신경만 생성함수\n",
    "def layer_9_model():\n",
    "    # 모델 생성\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolution & MaxPooling 층\n",
    "    # 2개의 층을 하나의 묶음으로 봄\n",
    "    # 1층\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), padding='same',\n",
    "                    activation='linear', input_shape=(img_rows, img_cols,3)))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    # 2층\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), padding='same',\n",
    "                   activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "    # 2개의 층을 하나의 묶음으로 봄\n",
    "    # 3층\n",
    "    model.add(Conv2D(64,kernel_size=(3,3), padding='same',\n",
    "                    activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    # 4층\n",
    "    model.add(Conv2D(64, kernel_size=(3,3),padding='same',\n",
    "                    activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "    # 5층\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding='same',\n",
    "                    activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    # 6층\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding='same',\n",
    "                    activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    # Flatten 층 (2차원 -> 1차원)\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # 전결합 & DropOut 층\n",
    "    model.add(Dense(1024, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1024, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "\n",
    "    # 출력층 (결과가 6종류이므로..)\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    # 컴파일 \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    # 구성확인\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 1장을 읽어오고 리사이징한다.\n",
    "def get_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (img_rows, img_cols))\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터를 읽어오는 함수\n",
    "def read_train_data(ho=0, kind='train'):\n",
    "    # 학습용 입력데이터를 담을 리스트\n",
    "    train_data = []\n",
    "    # 학습용 결과데이터를 담을 리스트\n",
    "    train_target = []\n",
    "    \n",
    "    # 결과 종류의 수만큼 반복한다.(비행기, 오토바이, 등등)\n",
    "    for j in range(0,6):\n",
    "        # 이미지의 경로\n",
    "        path = 'data/Caltech-101/'\n",
    "        path += f'{kind}/{ho}/*/{j}/*.jpg' # ex) train/0/0/*.jpg\n",
    "        \n",
    "        # 파일 목록을 가져온다.\n",
    "        files = sorted(glob.glob(path))\n",
    "        # print(files)\n",
    "        \n",
    "        # 파일의 수만큼 반복한다.\n",
    "        for f1 in files:\n",
    "            # 파일 이름을 가져온다.\n",
    "            file_base = os.path.basename(f1)\n",
    "            \n",
    "            # 이미지 1장을 읽어온다.\n",
    "            img = get_img(f1)\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            \n",
    "            # 데이터 정규화\n",
    "            img -= np.mean(img)\n",
    "            img /= np.std(img)\n",
    "            \n",
    "            # 리스트에 담는다.\n",
    "            train_data.append(img)\n",
    "            train_target.append(j)\n",
    "    \n",
    "    # 읽어들인 데이터를 numpy의 array로 변환\n",
    "    train_data = np.array(train_data, dtype=np.float32)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    \n",
    "    # target을 원핫 인코딩한다.\n",
    "    # 예) 1 -> 0,1,0,0,0,0\n",
    "    train_target = np_utils.to_categorical(train_target, 6)\n",
    "    \n",
    "    # 데이터를 섞는다.\n",
    "    perm = permutation(len(train_target))\n",
    "    train_data = train_data[perm]\n",
    "    train_target = train_target[perm]\n",
    "    \n",
    "    return train_data, train_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 구조와 가중치를 저장한다.\n",
    "def save_model(model, ho, modelStr=''):\n",
    "    \n",
    "    # 모델 객체를 json 형식으로 변환한다.\n",
    "    json_string = model.to_json()\n",
    "    \n",
    "    # cache 폴더가 없으면 만들어준다.\n",
    "    if not os.path.exists('cache'):\n",
    "        os.makedirs('cache')\n",
    "        \n",
    "    # 모델 구조를 저장하기 위한 파일명\n",
    "    json_name = f'architecture_{modelStr}_{ho}.json'\n",
    "    \n",
    "    # 모델 구조를 저장한다.\n",
    "    with open(os.path.join('cache', json_name),'w') as fp:\n",
    "        fp.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def run_train(modelStr=''):\n",
    "    # HoldOut을 두번 수행한다.\n",
    "    for ho in range(2):\n",
    "        # 모델을 생성한다.\n",
    "        model = layer_9_model()\n",
    "        \n",
    "        # 학습 데이터를 읽어온다. 함수호출\n",
    "        t_data, t_target = read_train_data(ho,'train') \n",
    "        # 검증 데이터를 읽어온다.\n",
    "        v_data, v_target = read_train_data(ho,'valid')\n",
    "        \n",
    "        # 매 epoch마다 모델을 저장하기 위한 callback을 생성한다.\n",
    "        cp = ModelCheckpoint(f'cache/model_weights_{modelStr}_{ho}_' + '{epoch:02d}.h5',\n",
    "                            monitor='val_loss', save_best_only=False)\n",
    "        \n",
    "        # train 실행\n",
    "        model.fit(t_data, t_target, batch_size=16, epochs=40,\n",
    "                 validation_data=(v_data, v_target), shuffle=True, callbacks=[cp])\n",
    "        \n",
    "        # 모델 구조 저장\n",
    "        save_model(model, ho, modelStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 104,104,230\n",
      "Trainable params: 104,104,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "82/82 [==============================] - 18s 147ms/step - loss: 2.0012 - accuracy: 0.3932 - val_loss: 1.1533 - val_accuracy: 0.6207\n",
      "Epoch 2/40\n",
      "82/82 [==============================] - 11s 135ms/step - loss: 1.0708 - accuracy: 0.6464 - val_loss: 1.1840 - val_accuracy: 0.5494\n",
      "Epoch 3/40\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 0.9641 - accuracy: 0.6481 - val_loss: 1.4332 - val_accuracy: 0.6398\n",
      "Epoch 4/40\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 0.7350 - accuracy: 0.7595 - val_loss: 1.6592 - val_accuracy: 0.4398\n",
      "Epoch 5/40\n",
      "82/82 [==============================] - 10s 118ms/step - loss: 0.6335 - accuracy: 0.7759 - val_loss: 1.5402 - val_accuracy: 0.6674\n",
      "Epoch 6/40\n",
      "82/82 [==============================] - 10s 119ms/step - loss: 0.3825 - accuracy: 0.8778 - val_loss: 1.4139 - val_accuracy: 0.6728\n",
      "Epoch 7/40\n",
      "82/82 [==============================] - 10s 124ms/step - loss: 0.1922 - accuracy: 0.9420 - val_loss: 1.6796 - val_accuracy: 0.6766\n",
      "Epoch 8/40\n",
      "82/82 [==============================] - 10s 127ms/step - loss: 0.3069 - accuracy: 0.9137 - val_loss: 3.1521 - val_accuracy: 0.5448\n",
      "Epoch 9/40\n",
      "82/82 [==============================] - 10s 116ms/step - loss: 0.4731 - accuracy: 0.8710 - val_loss: 2.2405 - val_accuracy: 0.5303\n",
      "Epoch 10/40\n",
      "82/82 [==============================] - 10s 117ms/step - loss: 0.4856 - accuracy: 0.8737 - val_loss: 2.5372 - val_accuracy: 0.5801\n",
      "Epoch 11/40\n",
      "82/82 [==============================] - 10s 120ms/step - loss: 0.6304 - accuracy: 0.8522 - val_loss: 2.6149 - val_accuracy: 0.5701\n",
      "Epoch 12/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 0.3661 - accuracy: 0.9075 - val_loss: 2.5433 - val_accuracy: 0.6000\n",
      "Epoch 13/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 0.6276 - accuracy: 0.8622 - val_loss: 4.0968 - val_accuracy: 0.4866\n",
      "Epoch 14/40\n",
      "82/82 [==============================] - 11s 128ms/step - loss: 0.4796 - accuracy: 0.8875 - val_loss: 3.7973 - val_accuracy: 0.5969\n",
      "Epoch 15/40\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 0.3960 - accuracy: 0.9354 - val_loss: 5.6918 - val_accuracy: 0.4897\n",
      "Epoch 16/40\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 0.5605 - accuracy: 0.8949 - val_loss: 4.5860 - val_accuracy: 0.5142\n",
      "Epoch 17/40\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 0.6041 - accuracy: 0.8923 - val_loss: 5.9653 - val_accuracy: 0.5816\n",
      "Epoch 18/40\n",
      "82/82 [==============================] - 11s 135ms/step - loss: 0.4155 - accuracy: 0.9441 - val_loss: 4.4365 - val_accuracy: 0.5586\n",
      "Epoch 19/40\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 0.2301 - accuracy: 0.9443 - val_loss: 7.8746 - val_accuracy: 0.5034\n",
      "Epoch 20/40\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 0.9878 - accuracy: 0.8812 - val_loss: 17.3186 - val_accuracy: 0.4230\n",
      "Epoch 21/40\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 541.1224 - accuracy: 0.6030 - val_loss: 446.6454 - val_accuracy: 0.4429\n",
      "Epoch 22/40\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 302.0010 - accuracy: 0.3543 - val_loss: 21.4828 - val_accuracy: 0.6245\n",
      "Epoch 23/40\n",
      "82/82 [==============================] - 11s 129ms/step - loss: 13.3380 - accuracy: 0.6302 - val_loss: 9.7475 - val_accuracy: 0.6613\n",
      "Epoch 24/40\n",
      "82/82 [==============================] - 10s 124ms/step - loss: 5.0462 - accuracy: 0.7539 - val_loss: 13.8341 - val_accuracy: 0.5793\n",
      "Epoch 25/40\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 5.3548 - accuracy: 0.7511 - val_loss: 8.7384 - val_accuracy: 0.6498\n",
      "Epoch 26/40\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 2.8566 - accuracy: 0.8098 - val_loss: 7.9220 - val_accuracy: 0.6690\n",
      "Epoch 27/40\n",
      "82/82 [==============================] - 11s 129ms/step - loss: 1.6125 - accuracy: 0.8695 - val_loss: 7.7023 - val_accuracy: 0.6958\n",
      "Epoch 28/40\n",
      "82/82 [==============================] - 10s 119ms/step - loss: 1.7061 - accuracy: 0.8695 - val_loss: 8.5480 - val_accuracy: 0.6705\n",
      "Epoch 29/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.8399 - accuracy: 0.9160 - val_loss: 7.6920 - val_accuracy: 0.6866\n",
      "Epoch 30/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.8674 - accuracy: 0.9179 - val_loss: 6.7686 - val_accuracy: 0.6935\n",
      "Epoch 31/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.6487 - accuracy: 0.9403 - val_loss: 7.9638 - val_accuracy: 0.6835\n",
      "Epoch 32/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 1.0950 - accuracy: 0.8898 - val_loss: 11.3345 - val_accuracy: 0.6475\n",
      "Epoch 33/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.5758 - accuracy: 0.9434 - val_loss: 8.2677 - val_accuracy: 0.6812\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 9s 112ms/step - loss: 0.4181 - accuracy: 0.9496 - val_loss: 8.4377 - val_accuracy: 0.6889\n",
      "Epoch 35/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.5385 - accuracy: 0.9535 - val_loss: 10.0031 - val_accuracy: 0.6897\n",
      "Epoch 36/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.6860 - accuracy: 0.9387 - val_loss: 9.6934 - val_accuracy: 0.6966\n",
      "Epoch 37/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.2352 - accuracy: 0.9727 - val_loss: 10.9085 - val_accuracy: 0.6897\n",
      "Epoch 38/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.6086 - accuracy: 0.9469 - val_loss: 10.6230 - val_accuracy: 0.6743\n",
      "Epoch 39/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.2984 - accuracy: 0.9699 - val_loss: 10.3207 - val_accuracy: 0.6866\n",
      "Epoch 40/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.4207 - accuracy: 0.9662 - val_loss: 9.6892 - val_accuracy: 0.6889\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 104,104,230\n",
      "Trainable params: 104,104,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "82/82 [==============================] - 10s 113ms/step - loss: 3.0429 - accuracy: 0.3432 - val_loss: 1.1131 - val_accuracy: 0.6230\n",
      "Epoch 2/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 1.0124 - accuracy: 0.6652 - val_loss: 1.0721 - val_accuracy: 0.6812\n",
      "Epoch 3/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.8145 - accuracy: 0.7226 - val_loss: 0.9605 - val_accuracy: 0.7027\n",
      "Epoch 4/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.5428 - accuracy: 0.8129 - val_loss: 1.4267 - val_accuracy: 0.5877\n",
      "Epoch 5/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.6652 - accuracy: 0.7827 - val_loss: 1.7074 - val_accuracy: 0.5632\n",
      "Epoch 6/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.5547 - accuracy: 0.8219 - val_loss: 1.5217 - val_accuracy: 0.5801\n",
      "Epoch 7/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.5147 - accuracy: 0.8501 - val_loss: 1.7604 - val_accuracy: 0.5027\n",
      "Epoch 8/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.6899 - accuracy: 0.7717 - val_loss: 1.7349 - val_accuracy: 0.5617\n",
      "Epoch 9/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.5509 - accuracy: 0.8396 - val_loss: 1.7569 - val_accuracy: 0.6276\n",
      "Epoch 10/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.3938 - accuracy: 0.8977 - val_loss: 2.9508 - val_accuracy: 0.5862\n",
      "Epoch 11/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.5892 - accuracy: 0.8699 - val_loss: 1.8405 - val_accuracy: 0.6000\n",
      "Epoch 12/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.2423 - accuracy: 0.9110 - val_loss: 2.1076 - val_accuracy: 0.6498\n",
      "Epoch 13/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.1319 - accuracy: 0.9650 - val_loss: 2.2651 - val_accuracy: 0.6475\n",
      "Epoch 14/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.0460 - accuracy: 0.9849 - val_loss: 3.3364 - val_accuracy: 0.5946\n",
      "Epoch 15/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.3080 - accuracy: 0.9451 - val_loss: 6.9915 - val_accuracy: 0.4383\n",
      "Epoch 16/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 54.2908 - accuracy: 0.6580 - val_loss: 122.8503 - val_accuracy: 0.2146\n",
      "Epoch 17/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 379.9372 - accuracy: 0.2608 - val_loss: 17.2917 - val_accuracy: 0.4015\n",
      "Epoch 18/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 14.9142 - accuracy: 0.3654 - val_loss: 3.2115 - val_accuracy: 0.5410\n",
      "Epoch 19/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 4.1512 - accuracy: 0.5306 - val_loss: 2.3354 - val_accuracy: 0.6460\n",
      "Epoch 20/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 2.2636 - accuracy: 0.5923 - val_loss: 2.5807 - val_accuracy: 0.6406\n",
      "Epoch 21/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 1.9077 - accuracy: 0.6327 - val_loss: 1.5351 - val_accuracy: 0.7203\n",
      "Epoch 22/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 1.1251 - accuracy: 0.6886 - val_loss: 2.3935 - val_accuracy: 0.7027\n",
      "Epoch 23/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 1.1151 - accuracy: 0.7201 - val_loss: 1.7123 - val_accuracy: 0.6989\n",
      "Epoch 24/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.8591 - accuracy: 0.7565 - val_loss: 1.3925 - val_accuracy: 0.6828\n",
      "Epoch 25/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.8893 - accuracy: 0.7279 - val_loss: 1.5842 - val_accuracy: 0.7425\n",
      "Epoch 26/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.5726 - accuracy: 0.8199 - val_loss: 1.7354 - val_accuracy: 0.7034\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 9s 112ms/step - loss: 0.7163 - accuracy: 0.7813 - val_loss: 3.0640 - val_accuracy: 0.5318\n",
      "Epoch 28/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 1.1130 - accuracy: 0.7306 - val_loss: 1.4249 - val_accuracy: 0.7372\n",
      "Epoch 29/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.6454 - accuracy: 0.8270 - val_loss: 1.8013 - val_accuracy: 0.7625\n",
      "Epoch 30/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.6193 - accuracy: 0.8248 - val_loss: 1.4759 - val_accuracy: 0.7525\n",
      "Epoch 31/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.4438 - accuracy: 0.8686 - val_loss: 1.7775 - val_accuracy: 0.7479\n",
      "Epoch 32/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.3504 - accuracy: 0.8813 - val_loss: 1.8401 - val_accuracy: 0.7142\n",
      "Epoch 33/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.4515 - accuracy: 0.8548 - val_loss: 1.7056 - val_accuracy: 0.7441\n",
      "Epoch 34/40\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 0.4191 - accuracy: 0.8676 - val_loss: 2.3569 - val_accuracy: 0.6559\n",
      "Epoch 35/40\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 0.4563 - accuracy: 0.8530 - val_loss: 2.1058 - val_accuracy: 0.7663\n",
      "Epoch 36/40\n",
      "82/82 [==============================] - 9s 114ms/step - loss: 0.3889 - accuracy: 0.8904 - val_loss: 2.2671 - val_accuracy: 0.7494\n",
      "Epoch 37/40\n",
      "82/82 [==============================] - 9s 114ms/step - loss: 0.3037 - accuracy: 0.9116 - val_loss: 1.9646 - val_accuracy: 0.7479\n",
      "Epoch 38/40\n",
      "82/82 [==============================] - 9s 115ms/step - loss: 0.2689 - accuracy: 0.9149 - val_loss: 1.6372 - val_accuracy: 0.7609\n",
      "Epoch 39/40\n",
      "82/82 [==============================] - 9s 114ms/step - loss: 0.1777 - accuracy: 0.9415 - val_loss: 2.2668 - val_accuracy: 0.7410\n",
      "Epoch 40/40\n",
      "82/82 [==============================] - 10s 122ms/step - loss: 0.3426 - accuracy: 0.9089 - val_loss: 1.9522 - val_accuracy: 0.7441\n"
     ]
    }
   ],
   "source": [
    "# CPU 실행\n",
    "# with tf.device('/CPU:0'):\n",
    "#     if run_type == 'train':\n",
    "#     run_train('9_Layer_CNN')\n",
    "# elif run_type == 'test':\n",
    "#     pass\n",
    "\n",
    "# GPU 실행\n",
    "# GPU 메모리 부족 에러 Failed to get convolution algorithm\n",
    "\n",
    "if run_type == 'train':\n",
    "    run_train('9_Layer_CNN')\n",
    "elif run_type == 'test':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
