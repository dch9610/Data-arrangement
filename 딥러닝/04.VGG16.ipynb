{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import permutation\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# VGG 16\n",
    "from keras.applications import VGG16\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# GPU 강제 할당\n",
    "# 사용 가능한 GPU 목록을 가져온다.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        # 필요한 만큼만 메모리를 사용할 수 있도록 설정한다.\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤시드 \n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용하는 이미지 사이즈\n",
    "img_rows = 224\n",
    "img_cols = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행모드\n",
    "run_type = 'train'\n",
    "# run_type = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 모델 확인 함수:\n",
    "def check_vgg16_model():\n",
    "    model = VGG16()\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 모델 생성 함수\n",
    "# 상황에 맞게 커스텀 가능\n",
    "def create_vgg16_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # VGG-16 모델과 동일하게 모델을 설계한다.\n",
    "    # 입력층 구조\n",
    "    input_shape= (img_rows, img_cols, 3)\n",
    "    \n",
    "    # 출력층 구조\n",
    "    output_node = 6\n",
    "    \n",
    "    # 신경망설계\n",
    "    # 64\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear', input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # 128\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear', input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # 256\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear', input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear', input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # 512\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear', input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear', input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear', input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear', input_shape=input_shape))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), padding='same', \n",
    "                     activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # Flatten 층\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # 전결합 & dropout 층\n",
    "    model.add(Dense(4096, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(4096, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # 출력층\n",
    "    model.add(Dense(output_node, activation='softmax'))\n",
    "    \n",
    "    # 컴파일 \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 학습이 완료된 VGG16 모델을 사용한다.\n",
    "def vgg16_model():\n",
    "    # 입력층 \n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    # 출력층\n",
    "    output_shape = 6\n",
    "    \n",
    "    # vgg16 모델을 불러온다.\n",
    "    # include_top : False를 넣어주면 입력층이 결정되지 않고\n",
    "    # Flatten 층부터 출력층까지 제거된다. 입력층과 출력을 다시 설계하고자 할때 사용한다.\n",
    "    # input_shape : 입력층 설계\n",
    "    # weights : 기존에 학습을 통해 구한 가중치값을 설정해준다.\n",
    "    vgg16_model = VGG16(include_top=False, input_shape=input_shape,\n",
    "                     weights = 'imagenet')\n",
    "    \n",
    "    # vgg16 모델이 새롭게 학습하는 것을 방지한다.\n",
    "    # 역전파가 vgg16 모델까지 도착하면 역전파를 중단 시키는 설정\n",
    "    # 이로 인해 vgg16모델에 셋팅된 가중치 값이 변경되지 않도록 한다.\n",
    "    vgg16_model.trainable = False\n",
    "    # vgg_model.summary()\n",
    "    \n",
    "    # 새로운 신경망을 생성한다.\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 위에서 생성한 VGG16 신경망을 붙인다.\n",
    "    model.add(vgg16_model)\n",
    "    \n",
    "    # Flatten 층\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # 전결합 & dropout 층\n",
    "    model.add(Dense(4096, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(4096, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # 출력층\n",
    "    model.add(Dense(output_shape, activation='softmax'))\n",
    "    \n",
    "    # 컴파일 \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 134,285,126\n",
      "Trainable params: 119,570,438\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x13a13307ee0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 1장을 읽어오고 리사이징한다.\n",
    "def get_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (img_rows, img_cols))\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터를 읽어오는 함수\n",
    "def read_train_data(ho=0, kind='train'):\n",
    "    # 학습용 입력데이터를 담을 리스트\n",
    "    train_data = []\n",
    "    # 학습용 결과데이터를 담을 리스트\n",
    "    train_target = []\n",
    "    \n",
    "    # 결과 종류의 수만큼 반복한다.(비행기, 오토바이, 등등)\n",
    "    for j in range(0,6):\n",
    "        # 이미지의 경로\n",
    "        path = 'data/Caltech-101/'\n",
    "        path += f'{kind}/{ho}/*/{j}/*.jpg' # ex) train/0/0/*.jpg\n",
    "        \n",
    "        # 파일 목록을 가져온다.\n",
    "        files = sorted(glob.glob(path))\n",
    "        # print(files)\n",
    "        \n",
    "        # 파일의 수만큼 반복한다.\n",
    "        for f1 in files:\n",
    "            # 파일 이름을 가져온다.\n",
    "            file_base = os.path.basename(f1)\n",
    "            \n",
    "            # 이미지 1장을 읽어온다.\n",
    "            img = get_img(f1)\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            \n",
    "            # 데이터 정규화\n",
    "            img -= np.mean(img)\n",
    "            img /= np.std(img)\n",
    "            \n",
    "            # 리스트에 담는다.\n",
    "            train_data.append(img)\n",
    "            train_target.append(j)\n",
    "    \n",
    "    # 읽어들인 데이터를 numpy의 array로 변환\n",
    "    train_data = np.array(train_data, dtype=np.float32)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    \n",
    "    # target을 원핫 인코딩한다.\n",
    "    # 예) 1 -> 0,1,0,0,0,0\n",
    "    train_target = np_utils.to_categorical(train_target, 6)\n",
    "    \n",
    "    # 데이터를 섞는다.\n",
    "    perm = permutation(len(train_target))\n",
    "    train_data = train_data[perm]\n",
    "    train_target = train_target[perm]\n",
    "    \n",
    "    return train_data, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 구조와 가중치를 저장한다.\n",
    "def save_model(model, ho, modelStr=''):\n",
    "    \n",
    "    # 모델 객체를 json 형식으로 변환한다.\n",
    "    json_string = model.to_json()\n",
    "    \n",
    "    # cache 폴더가 없으면 만들어준다.\n",
    "    if not os.path.exists('cache'):\n",
    "        os.makedirs('cache')\n",
    "        \n",
    "    # 모델 구조를 저장하기 위한 파일명\n",
    "    json_name = f'architecture_{modelStr}_{ho}.json'\n",
    "    \n",
    "    # 모델 구조를 저장한다.\n",
    "    with open(os.path.join('cache', json_name),'w') as fp:\n",
    "        fp.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def run_train(modelStr=''):\n",
    "    # HoldOut을 두번 수행한다.\n",
    "    for ho in range(2):\n",
    "        # 모델을 생성한다.\n",
    "        model = vgg16_model()\n",
    "        \n",
    "        # 학습 데이터를 읽어온다. 함수호출\n",
    "        t_data, t_target = read_train_data(ho,'train') \n",
    "        # 검증 데이터를 읽어온다.\n",
    "        v_data, v_target = read_train_data(ho,'valid')\n",
    "        \n",
    "        # 매 epoch마다 모델을 저장하기 위한 callback을 생성한다.\n",
    "        # save_best_only = True : 손실률을 비교하여 가장 적은 모델을 저장해나감\n",
    "        cp = ModelCheckpoint(f'cache/model_weights_{modelStr}_{ho}_' + '{epoch:02d}.h5',\n",
    "                            monitor='val_loss', save_best_only=True)\n",
    "        \n",
    "        # train 실행\n",
    "        model.fit(t_data, t_target, batch_size=16, epochs=40,\n",
    "                 validation_data=(v_data, v_target), shuffle=True, callbacks=[cp])\n",
    "        \n",
    "        # 모델 구조 저장\n",
    "        save_model(model, ho, modelStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test용 이미지를 불러오는 함수\n",
    "def load_test(test_class, aug_i):\n",
    "    # 경로\n",
    "    path = f'data/Caltech-101/test/{aug_i}/{test_class}/*.jpg'\n",
    "    \n",
    "    # 파일 목록을 가져온다.\n",
    "    files = sorted(glob.glob(path))\n",
    "    # display(files)\n",
    "    \n",
    "    # 이미지 데이터를 담을 리스트\n",
    "    X_test = []\n",
    "    # 결과데이터를 담을 리스트\n",
    "    X_test_id = []\n",
    "    \n",
    "    # 파일의 수만큼 반복한다.\n",
    "    for f1 in files:\n",
    "        # 파일의 이름을 가져온다.\n",
    "        f1base = os.path.basename(f1)\n",
    "        \n",
    "        # 이미지 데이터를 가져온다.\n",
    "        img = get_img(f1)\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        \n",
    "        # 정규화\n",
    "        img -= np.mean(img)\n",
    "        img /= np.std(img)\n",
    "        \n",
    "        # 담는다.\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(f1base)\n",
    "     \n",
    "    # 읽어들인 데이터를 ndarray 최종변환\n",
    "    test_data = np.array(X_test, dtype=np.float32)\n",
    "    \n",
    "    return test_data, X_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델을 복원하는 함수\n",
    "def read_model(ho, modelStr='', epoch='00'):\n",
    "    # 모델 구조의 파일명\n",
    "    json_name = f'cache/architecture_{modelStr}_{ho}.json'\n",
    "    \n",
    "    # 모델 가중치 파일명\n",
    "    weight_name = f'cache/model_weights_{modelStr}_{ho}_{epoch}.h5'\n",
    "    \n",
    "    # 모델 구조를 json으로부터 읽어 복원한다.\n",
    "    model = model_from_json(open(json_name).read())\n",
    "    \n",
    "    # 복원된 모델에 가중치값을 셋팅한다.\n",
    "    model.load_weights(weight_name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 함수\n",
    "def run_test(modelStr, epoch1, epoch2):\n",
    "    # 결과 데이터 불러오기\n",
    "    columns = []\n",
    "    \n",
    "    # 파일에서 데이터를 읽어온다.\n",
    "    with open ('data/Caltech-101/label.csv','r') as fp:\n",
    "        line = fp.readline()\n",
    "    display(line)\n",
    "    \n",
    "    # 쉼표 (,)를 기준으로 잘라낸다.\n",
    "    sp = line.split(',')\n",
    "    # 잘라낸 문장만큼 반복한다.\n",
    "    for c1 in sp:\n",
    "        # 콜론(:)을 기준으로 잘라낸다.\n",
    "        sp2 = c1.split(':')\n",
    "        columns.append(sp2[1])\n",
    "        \n",
    "    print(columns)\n",
    "            \n",
    "    # 테스트 데이터가 각 클래스로 나누어지므로\n",
    "    # 1 클래스씩 읽어서 예측을 실행한다.\n",
    "    for test_class in range(0, 6):\n",
    "        # 예측된 결과를 담을 리스트\n",
    "        yfull_test = []\n",
    "        \n",
    "        # 하나의 이미지가 5번 변환되어 있으므로 이 수만큼 반복한다.\n",
    "        for aug_i in range(0,5):\n",
    "            # 예측할 이미지 데이터를 불러온다.\n",
    "            test_data, test_id = load_test(test_class, aug_i)\n",
    "            # display(test_id)\n",
    "            \n",
    "            # 홀드아웃 수만큼 반복한다.\n",
    "            for ho in range(2):\n",
    "                # 모델을 복원한다.\n",
    "                if ho == 0:\n",
    "                    n_epoch = epoch1\n",
    "                else:\n",
    "                    n_epoch = epoch2\n",
    "                    \n",
    "                model = read_model(ho, modelStr, n_epoch)\n",
    "                # display(model)\n",
    "                \n",
    "                # 예측을 실행한다.\n",
    "                test_p = model.predict(test_data, batch_size=32, verbose=1)\n",
    "                \n",
    "                # 예측된 결과를 담는다.\n",
    "                yfull_test.append(test_p)\n",
    "                \n",
    "        # 예측(상위 10개) 결과의 평균을 구한다.\n",
    "        test_res = np.array(yfull_test[0])\n",
    "        for i in range(1,10):\n",
    "            test_res = np.array(yfull_test[1])\n",
    "            \n",
    "        test_res /= 10\n",
    "        \n",
    "        # 예측결과와 클래스명, 이미지명을 합함\n",
    "        result1 = pd.DataFrame(test_res, columns=columns)\n",
    "        result1.loc[:,'img'] = pd.Series(test_id, index = result1.index)\n",
    "        \n",
    "        # 저장한다.\n",
    "        if not os.path.exists('subm'):\n",
    "            os.makedirs('subm')\n",
    "        sub_file = f'subm/result_{modelStr}_{test_class}.csv'\n",
    "        result1.to_csv(sub_file, index=False)\n",
    "        \n",
    "        # 위에서 구한 예측 정확도가 가장 높은것을 가져온다.\n",
    "        a1 = np.argmax(test_res, axis=1)\n",
    "        \n",
    "        # 정답수와 오답수를 구한다.\n",
    "        one_column = np.where(a1 == test_class)\n",
    "        \n",
    "        print(f'정답수 : {len(one_column[0])}')\n",
    "        print(f'오답수 : {test_res.shape[0] - len(one_column[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 134,285,126\n",
      "Trainable params: 119,570,438\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "82/82 [==============================] - 24s 180ms/step - loss: 34.3974 - accuracy: 0.5202 - val_loss: 9.7239 - val_accuracy: 0.8215\n",
      "Epoch 2/40\n",
      "82/82 [==============================] - 12s 149ms/step - loss: 4.2095 - accuracy: 0.9015 - val_loss: 16.6740 - val_accuracy: 0.8391\n",
      "Epoch 3/40\n",
      "82/82 [==============================] - 12s 152ms/step - loss: 12.3918 - accuracy: 0.8748 - val_loss: 34.6719 - val_accuracy: 0.8743\n",
      "Epoch 4/40\n",
      "82/82 [==============================] - 12s 151ms/step - loss: 15.8624 - accuracy: 0.9203 - val_loss: 42.3181 - val_accuracy: 0.9027\n",
      "Epoch 5/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 19.2709 - accuracy: 0.9352 - val_loss: 30.4068 - val_accuracy: 0.9172\n",
      "Epoch 6/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 25.5441 - accuracy: 0.9425 - val_loss: 89.6619 - val_accuracy: 0.8605\n",
      "Epoch 7/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 22.5773 - accuracy: 0.9594 - val_loss: 66.2708 - val_accuracy: 0.9019\n",
      "Epoch 8/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 19.0894 - accuracy: 0.9704 - val_loss: 136.0228 - val_accuracy: 0.8828\n",
      "Epoch 9/40\n",
      "82/82 [==============================] - 12s 149ms/step - loss: 25.9145 - accuracy: 0.9580 - val_loss: 331.3080 - val_accuracy: 0.8061\n",
      "Epoch 10/40\n",
      "82/82 [==============================] - 12s 150ms/step - loss: 124.7670 - accuracy: 0.9271 - val_loss: 84.9555 - val_accuracy: 0.9395\n",
      "Epoch 11/40\n",
      "82/82 [==============================] - 12s 153ms/step - loss: 34.3897 - accuracy: 0.9765 - val_loss: 110.6136 - val_accuracy: 0.9333\n",
      "Epoch 12/40\n",
      "82/82 [==============================] - 12s 152ms/step - loss: 54.5227 - accuracy: 0.9672 - val_loss: 209.0577 - val_accuracy: 0.9180\n",
      "Epoch 13/40\n",
      "82/82 [==============================] - 12s 148ms/step - loss: 3.1248 - accuracy: 0.9941 - val_loss: 99.9534 - val_accuracy: 0.9441\n",
      "Epoch 14/40\n",
      "82/82 [==============================] - 12s 153ms/step - loss: 21.3692 - accuracy: 0.9869 - val_loss: 243.2924 - val_accuracy: 0.9126\n",
      "Epoch 15/40\n",
      "82/82 [==============================] - 12s 150ms/step - loss: 16.8793 - accuracy: 0.9892 - val_loss: 113.9074 - val_accuracy: 0.9418\n",
      "Epoch 16/40\n",
      "82/82 [==============================] - 12s 150ms/step - loss: 20.9279 - accuracy: 0.9854 - val_loss: 154.6359 - val_accuracy: 0.9456\n",
      "Epoch 17/40\n",
      "82/82 [==============================] - 12s 151ms/step - loss: 15.0922 - accuracy: 0.9911 - val_loss: 117.1776 - val_accuracy: 0.9540\n",
      "Epoch 18/40\n",
      "82/82 [==============================] - 12s 149ms/step - loss: 22.8088 - accuracy: 0.9913 - val_loss: 235.2099 - val_accuracy: 0.9333\n",
      "Epoch 19/40\n",
      "82/82 [==============================] - 12s 149ms/step - loss: 32.7696 - accuracy: 0.9819 - val_loss: 273.8456 - val_accuracy: 0.9188\n",
      "Epoch 20/40\n",
      "82/82 [==============================] - 12s 148ms/step - loss: 40.4872 - accuracy: 0.9842 - val_loss: 202.3438 - val_accuracy: 0.9310\n",
      "Epoch 21/40\n",
      "82/82 [==============================] - 12s 151ms/step - loss: 39.2047 - accuracy: 0.9851 - val_loss: 193.1234 - val_accuracy: 0.9464\n",
      "Epoch 22/40\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 26.9603 - accuracy: 0.9904 - val_loss: 353.0359 - val_accuracy: 0.9318\n",
      "Epoch 23/40\n",
      "82/82 [==============================] - 12s 153ms/step - loss: 39.2389 - accuracy: 0.9888 - val_loss: 325.7810 - val_accuracy: 0.9379\n",
      "Epoch 24/40\n",
      "82/82 [==============================] - 12s 152ms/step - loss: 51.5124 - accuracy: 0.9868 - val_loss: 211.5308 - val_accuracy: 0.9494\n",
      "Epoch 25/40\n",
      "82/82 [==============================] - 12s 150ms/step - loss: 22.6266 - accuracy: 0.9934 - val_loss: 491.7397 - val_accuracy: 0.9264\n",
      "Epoch 26/40\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 59.0588 - accuracy: 0.9897 - val_loss: 715.8730 - val_accuracy: 0.8958\n",
      "Epoch 27/40\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 124.7105 - accuracy: 0.9760 - val_loss: 569.3959 - val_accuracy: 0.9241\n",
      "Epoch 28/40\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 58.2961 - accuracy: 0.9914 - val_loss: 580.2393 - val_accuracy: 0.9318\n",
      "Epoch 29/40\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 90.4412 - accuracy: 0.9776 - val_loss: 652.6185 - val_accuracy: 0.9188\n",
      "Epoch 30/40\n",
      "82/82 [==============================] - 12s 149ms/step - loss: 66.2911 - accuracy: 0.9923 - val_loss: 677.6268 - val_accuracy: 0.9257\n",
      "Epoch 31/40\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 41.9371 - accuracy: 0.9913 - val_loss: 297.1816 - val_accuracy: 0.9563\n",
      "Epoch 32/40\n",
      "82/82 [==============================] - 12s 151ms/step - loss: 2.9631 - accuracy: 0.9981 - val_loss: 504.3017 - val_accuracy: 0.9410\n",
      "Epoch 33/40\n",
      "82/82 [==============================] - 12s 150ms/step - loss: 0.3899 - accuracy: 0.9999 - val_loss: 358.3876 - val_accuracy: 0.9540\n",
      "Epoch 34/40\n",
      "82/82 [==============================] - 12s 152ms/step - loss: 3.2651 - accuracy: 0.9982 - val_loss: 407.6624 - val_accuracy: 0.9517\n",
      "Epoch 35/40\n",
      "82/82 [==============================] - 12s 152ms/step - loss: 7.1595 - accuracy: 0.9972 - val_loss: 668.7866 - val_accuracy: 0.9318\n",
      "Epoch 36/40\n",
      "82/82 [==============================] - 12s 153ms/step - loss: 43.9251 - accuracy: 0.9896 - val_loss: 764.6937 - val_accuracy: 0.9356\n",
      "Epoch 37/40\n",
      "82/82 [==============================] - 12s 152ms/step - loss: 14.0917 - accuracy: 0.9966 - val_loss: 424.2859 - val_accuracy: 0.9571\n",
      "Epoch 38/40\n",
      "82/82 [==============================] - 12s 152ms/step - loss: 26.5559 - accuracy: 0.9945 - val_loss: 1553.9735 - val_accuracy: 0.8973\n",
      "Epoch 39/40\n",
      "82/82 [==============================] - 12s 143ms/step - loss: 25.4725 - accuracy: 0.9916 - val_loss: 333.8773 - val_accuracy: 0.9655\n",
      "Epoch 40/40\n",
      "82/82 [==============================] - 11s 135ms/step - loss: 12.4591 - accuracy: 0.9969 - val_loss: 530.4192 - val_accuracy: 0.9556\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 134,285,126\n",
      "Trainable params: 119,570,438\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "82/82 [==============================] - 12s 140ms/step - loss: 34.8150 - accuracy: 0.4992 - val_loss: 3.5471 - val_accuracy: 0.8981\n",
      "Epoch 2/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 5.0174 - accuracy: 0.9083 - val_loss: 6.1651 - val_accuracy: 0.8958\n",
      "Epoch 3/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 5.3536 - accuracy: 0.9233 - val_loss: 12.3445 - val_accuracy: 0.9042\n",
      "Epoch 4/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 9.6428 - accuracy: 0.9270 - val_loss: 82.4190 - val_accuracy: 0.7747\n",
      "Epoch 5/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 16.6085 - accuracy: 0.9350 - val_loss: 31.5168 - val_accuracy: 0.9088\n",
      "Epoch 6/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 32.6807 - accuracy: 0.9219 - val_loss: 117.0322 - val_accuracy: 0.8483\n",
      "Epoch 7/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 27.6362 - accuracy: 0.9572 - val_loss: 84.5767 - val_accuracy: 0.9096\n",
      "Epoch 8/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 50.2964 - accuracy: 0.9443 - val_loss: 41.8195 - val_accuracy: 0.9448\n",
      "Epoch 9/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 36.1311 - accuracy: 0.9584 - val_loss: 90.1019 - val_accuracy: 0.9326\n",
      "Epoch 10/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 15.8422 - accuracy: 0.9743 - val_loss: 214.2653 - val_accuracy: 0.8766\n",
      "Epoch 11/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 33.4260 - accuracy: 0.9675 - val_loss: 315.7143 - val_accuracy: 0.8935\n",
      "Epoch 12/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 44.5469 - accuracy: 0.9681 - val_loss: 127.0912 - val_accuracy: 0.9318\n",
      "Epoch 13/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 8.8299 - accuracy: 0.9959 - val_loss: 240.2289 - val_accuracy: 0.8989\n",
      "Epoch 14/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 45.2165 - accuracy: 0.9726 - val_loss: 289.9134 - val_accuracy: 0.9126\n",
      "Epoch 15/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 44.9190 - accuracy: 0.9801 - val_loss: 216.5416 - val_accuracy: 0.9341\n",
      "Epoch 16/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 24.8275 - accuracy: 0.9815 - val_loss: 311.0985 - val_accuracy: 0.9249\n",
      "Epoch 17/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 44.8062 - accuracy: 0.9831 - val_loss: 376.2139 - val_accuracy: 0.8797\n",
      "Epoch 18/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 51.9222 - accuracy: 0.9780 - val_loss: 420.1273 - val_accuracy: 0.8897\n",
      "Epoch 19/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 126.3340 - accuracy: 0.9718 - val_loss: 253.7206 - val_accuracy: 0.9502\n",
      "Epoch 20/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 54.3476 - accuracy: 0.9882 - val_loss: 236.6973 - val_accuracy: 0.9502\n",
      "Epoch 21/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 8.7731 - accuracy: 0.9979 - val_loss: 228.9006 - val_accuracy: 0.9487\n",
      "Epoch 22/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 7.5001 - accuracy: 0.9966 - val_loss: 275.0004 - val_accuracy: 0.9448\n",
      "Epoch 23/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 5.9395 - accuracy: 0.9960 - val_loss: 315.9100 - val_accuracy: 0.9333\n",
      "Epoch 24/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 21.8610 - accuracy: 0.9919 - val_loss: 395.4374 - val_accuracy: 0.9203\n",
      "Epoch 25/40\n",
      "82/82 [==============================] - 12s 143ms/step - loss: 35.2811 - accuracy: 0.9905 - val_loss: 266.1451 - val_accuracy: 0.9356\n",
      "Epoch 26/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 3.7719 - accuracy: 0.9990 - val_loss: 144.3156 - val_accuracy: 0.9663\n",
      "Epoch 27/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 11.1621 - accuracy: 0.9973 - val_loss: 207.6236 - val_accuracy: 0.9525\n",
      "Epoch 28/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 2.5553 - accuracy: 0.9987 - val_loss: 310.2902 - val_accuracy: 0.9387\n",
      "Epoch 29/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 10.6293 - accuracy: 0.9963 - val_loss: 677.1556 - val_accuracy: 0.9165\n",
      "Epoch 30/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 21.3788 - accuracy: 0.9895 - val_loss: 524.6178 - val_accuracy: 0.9402\n",
      "Epoch 31/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 176.2626 - accuracy: 0.9826 - val_loss: 317.1757 - val_accuracy: 0.9533\n",
      "Epoch 32/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 8.6301 - accuracy: 0.9959 - val_loss: 367.1806 - val_accuracy: 0.9448\n",
      "Epoch 33/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 36.2802 - accuracy: 0.9913 - val_loss: 354.5646 - val_accuracy: 0.9448\n",
      "Epoch 34/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 17.3468 - accuracy: 0.9946 - val_loss: 443.4506 - val_accuracy: 0.9517\n",
      "Epoch 35/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 55.5363 - accuracy: 0.9891 - val_loss: 340.7329 - val_accuracy: 0.9571\n",
      "Epoch 36/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 41.3582 - accuracy: 0.9961 - val_loss: 1524.9227 - val_accuracy: 0.8866\n",
      "Epoch 37/40\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 180.2837 - accuracy: 0.9678 - val_loss: 1268.1007 - val_accuracy: 0.9103\n",
      "Epoch 38/40\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 53.5774 - accuracy: 0.9926 - val_loss: 615.0302 - val_accuracy: 0.9494\n",
      "Epoch 39/40\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 2.2213 - accuracy: 0.9991 - val_loss: 619.5450 - val_accuracy: 0.9510\n",
      "Epoch 40/40\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 634.7227 - val_accuracy: 0.9479\n"
     ]
    }
   ],
   "source": [
    "# CPU 실행\n",
    "# with tf.device('/CPU:0'):\n",
    "#     if run_type == 'train':\n",
    "#     run_train('9_Layer_CNN')\n",
    "# elif run_type == 'test':\n",
    "#     pass\n",
    "\n",
    "# GPU 실행\n",
    "# GPU 메모리 부족 에러 Failed to get convolution algorithm\n",
    "with tf.device('/GPU:0'):\n",
    "    if run_type == 'train':\n",
    "        run_train('VGG16')\n",
    "    elif run_type == 'test':\n",
    "        run_test('VGG16','40','40')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
